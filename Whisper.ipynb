{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709e020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/desot1/opt/anaconda3/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" So today I'd like to talk about what we're building at DSI Labs, which is going to be one of those DSI apps that's building on all the cool infrastructure that everybody else is building here. And particularly I want to talk about how our new program called Note Stewards is going to help transform big scientific data into interoperable research objects that are stored open state on this cool infrastructure that we just heard about. So yeah, do you see in those ecosystems really cool as pop in? Lots of cool projects, many more I forgot a bunch, but yeah, Jocelyn is always curating this cool landscape, so just check it out. I have the Twitter right there. And yeah, so we just heard about it. So sharing scientific data is super important. Why? Because, well, if we share data, we can collaborate much more easily. We can build bigger data sets and bigger data sets means more statistical power, reliable results, right? So that's pretty cool. And it also means more access to the data that, so there's not the same access to cool instruments that help you with data collection across labs. So if you're in an underfunded research institution, you just may not have the ability to collect the same type of data that a well-funded institution may have. So if we all share data, we all have better access to make cool scientific discoveries. So that's pretty cool, right? But also sharing scientific data right now. It's pretty expensive, it's pretty vulnerable because it's stored on centralized databases where we just have to trust that they keep the database running. It's also not rewarded. So currently, what counts in science is having your PDF cited, but it doesn't matter if you make your data accessible, like you just cannot accrue credit to it. Or there's some ways you can, but it's just not really easy. And it's also pretty painful. So there's a couple of repos out there where you can store your data. These are funded by some governmental institutions. There you access not great. And then also, if you want to find the data, you need to know which repo it's stored at. So you need to find the repo. Then you need to find the data. It's all, it's a hassle, so it's not great. So what I'm hoping to convince you off is that sharing scientific data is great if you're using design nodes, right? So what is design nodes? That's what we're building at design labs. And basically, it's a way for you to collect all your artifacts that are relevant to a specific piece of research that are currently scattered across the internet and different silo data repos, but also maybe not even be published. And you can collect all that in one design node. You can connect all the different artifacts that are relevant to this research. You can connect your code to your data. You can link that all to the relevant sections in your PDF and your manuscript. And that way, you can create a reproducible research object. And the cool thing is, then if you publish it, it will become part of this open state repository that is based on decentralized storage solutions where you can even have different nodes interact. And one node, for example, citing the data set of another node, citing the code analysis of another node, and then coming up with new results based on that. So it's a very interactive scientific ecosystem, which that's how it should be. I feel so yeah, I'd love to show you guys a demo. So let's hope this works. So the idea is that that's how you find knowledge right now, right? So you go to some journal's website, you look for the PDF, and then you click on it, you find the PDF. So this is how research currently gets shared. You have this PDF, it's static. You're not really, you're lacking a bit of context. So somebody could download this and send it to you, read it, but you can't really tell how this has been updated. This is up to date, hasn't maybe even been retracted. And with this PDF, it's kind of cool, because you have this little button right here, which will always take you back to desynodes, where you have all the context that was relevant to this piece of research. So you get the idea, right? So you have interconnection. That is running on cool projects. Like, Buckley, I'll show you a demo if you come to me later. This kind of sucks. Anyways, so now I want to talk about Node Stewards. Node Stewards is our community program with which we're hoping to get actual scientists into the world of desi, show them what we can build if we use decentralized solutions for science, and then hopefully convince them of the whole value proposition. So Node Stewards are our program to help scientists on board into desi use this new technology. And they're going to do that by creating the first 100 desi nodes. And so I'm going to walk you through how we're trying to implement this project. So this is step one that's where we're at right now. So currently we're in the phase we're trying to identify the most valuable research. What does that mean? That means we're trying to find research that will have the most immediate benefit from adopting these solutions. And so that's likely going to be a empirical work with large data sets with non-districted data. So we don't run into GDPR issues. And hopefully a high impact research just because it's better visibility. So once we have identified the most important fields of research and the coolest researchers who are willing to maybe try this tech, we're going to collaborate with them. We're going to get their consent because yes, we're looking for research that's open access and permissively licensed. But we still want to get their consent because we're going to work with them and not step on anybody's toes. And then we're going to collaborate closely with them to teach and learn. So we're going to teach them about our tech and we're going to learn from them about their research areas, their problems, their issues, and how we can help them. And then together with them we're going to start collecting artifacts. So collect the code, collect the databases, collect anything else that's related to their research. So we want to put up on desi nodes. And this is important because currently as I said, much of the artifacts are relevant to research and not necessarily publicly available. And that's what we're trying to fix. So we're going to work with scientists to identify those artifacts. And then once we're there, next step is to actually go and create these 100 stellar desi nodes. So we're going to connect all the artifacts that's going to enable one click reproducibility, which you would know exactly what I mean if I was able to show you the demo. And we're going to also create artwork that we're going to tie to this research just to make it a bit, you know, make it a bit more cool. And then we're placing high value and making all the research that we publish on desi nodes fair. And fair means findable, accessible, interoperable, and reusable. And that's going to lead to good machine readability, which just helps you find the researcher. You're looking for, find the data set that you're looking for, and just use all the artifacts that are already out there to then better create your own research. Then we're going to publish all that to the IPFS network. And then we're going to let the authors of the work claim their work as authors. And yeah, so step zero, this is a consensus up there we're going to be implementing all the time is just building communities. So we have a couple of really engaged community members, who were super grateful for who are willing to help us with this project and create the first nodes. And yeah, so we're onboarding stewards on a rolling basis. So if you're interested, hit me up. And then we're facilitating connections between these stewards because there's so much opportunities for us to teach and learn from each other. So we have a really cool community of people who are a web free native scientist. We have actually data stewards themselves whose actual job it is to work with researchers to understand and help them implement the data requirements that they have for sharing the data. We have artists, so we have a bunch of cool people and we can just learn together and have a good time together. Well, we nerd out on research, so that's kind of cool. So yeah, what did we learn in the process? Actually, there's a bunch of people who want to fix science. And I think that applies to many of you here in the room. And we can leverage that momentum that's there by just giving these people the tools and the means to then actually go ahead and help starting to fix science. Another point that we learned is that if you have a diverse community from different fields, that just helps you understand your users a lot better. So we have been talking to our community and just most of them are scientists. So we learn a lot about what are the specific problems that they're having with sharing their data. So that's super, super helpful. And yeah, just in general, communities are super powerful and we need to nourish them. So let's do our best to do just that. So yeah, and then back to the ecosystem. So if we on-board scientists with this Node Stewards program that just helps the entire ecosystem because as I said, there's so many cool projects out there. So if we get more scientists in the space, then they're going to use all the other cool projects and we can all help each other and work together and doing that. So yeah, if you're interested in becoming a Node Stewards, join us. You can go to desifoundation.org slash Stewards. You can also reach out to me or follow desiLabs on Twitter. Thank you.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "path = '/Users/desot1/Documents/transcript_project/training_transcripts/'\n",
    "\n",
    "def GetTranscriptFromAudio(path, audiofilename):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(path + audiofilename)\n",
    "    F = open(path + audiofilename + \".txt\", \"w\")\n",
    "    F.write(result[\"text\"])\n",
    "    F.close()\n",
    "    # Return the transcript\n",
    "    transcript_text= result[\"text\"]\n",
    "    return transcript_text\n",
    "\n",
    "GetTranscriptFromAudio(path, \"carla.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4780b",
   "metadata": {},
   "source": [
    "Oki what I need to do is -> \n",
    "- Diaraize\n",
    "- Send each diarized chunk through whisper (in the segments format) + add \"\\n\" to each new line. \n",
    "- Check the length -> Split in x chunks based on size. \n",
    "- Check for periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528f6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torchvision is not available - cannot save figures\n",
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with Apple clang version 14.0.0 (clang-1400.0.29.102)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/5.1.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-neon\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'chris.wav':\n",
      "  Metadata:\n",
      "    artist          : ResearchHub\n",
      "    comment         : https://www.youtube.com/watch?v=pvDwP21TyCM\n",
      "    date            : 20221102\n",
      "    title           : Open Verifiability | Christopher Hill | DeSci Labs | SciCon 2022\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:31:00.23, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'chris_converted.wav':\n",
      "  Metadata:\n",
      "    IART            : ResearchHub\n",
      "    ICMT            : https://www.youtube.com/watch?v=pvDwP21TyCM\n",
      "    ICRD            : 20221102\n",
      "    INAM            : Open Verifiability | Christopher Hill | DeSci Labs | SciCon 2022\n",
      "    ISFT            : Lavf59.27.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 pcm_s16le\n",
      "size=   58132kB time=00:31:00.23 bitrate= 256.0kbits/s speed=1.67e+03x    \n",
      "video:0kB audio:58132kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000407%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav file: chris_converted.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/desot1/.cache/torch/hub/snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d23b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let import the most necessary libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Library to import pre-trained model for sentence embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Calculate similarities between sentences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Visualization library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# package for finding local minimas\n",
    "from scipy.signal import argrelextrema\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "15dfa28357c383de2362b161dae311c2d38370c3e7fa61c51d1dc413afafed6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
