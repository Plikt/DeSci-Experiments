So up next we have the CEO and co-founder from D.Sai Labs, Christopher Hill speaking about open verifulls. Chris is the best. The half towards a more reputable scientific record which returns value to the scientific community is kind of what Adam was just talking about. So Chris great to have you just a little background on Chris here. Chris is a co-founder of D.Sai Labs and an interdisciplinary scientist who's worked at the Crossroads of neuroscience economics and machine learning. He has a PhD in neuro economics and a couple of cool papers of publishing big journals. So Chris great to have you here. 
Hey great to be here. Yeah super excited thanks a lot for organizing all of this Patrick. We've had some really great speakers up to now. 
So so today I'm going to talk about open verifiability and how this could promote a more reproducible scientific record which returns value to scientists. So the first thing I want to frame out is the broader problem beyond funding of science beyond the questions of prestige and academia but really go towards the the threat that our epistemic comments or information sphere is facing at the moment. Their under threat trusted intermediaries used to play a critical role and still do today to some degree in curating research and knowledge and you'd have that process typically be handled by a journal who would conduct peer review over multiple months at the behest of the authors then that curation process would trickle out to the press to journalists who would report about it for example in New York Times it would then go up to policy makers who for example you know people working at a federal reserves or or underster. So there's that's our information supply chain essentially and it's not foolproof right there's been some spectacular failures of that information supply chains over the years and you know we have for example right now the unraveling of the Alzheimer's house of cards with the bedtime lawyer to hypothesis and other key papers that have been found you know to contain image fabrication under signs of fraud which are calling into question you know whole edifices of science and these are you know hundreds of millions of dollars that have been invested into that. This trusted intermediary model has suffered from two major systemic failures. 
The first one and the most important one is the replication crisis. There's a raging replication crisis out there papers simply don't replicate John Jan Eidas you know wrote a famous paper why most research findings are false and there's essentially a lot of work to be done to improve the reproducibility of research in general and the other major issue is that the publishing industry has consolidated in a few publishers who have a monopoly on knowledge and exploit that monopoly with libraries and other funders and exploit scientists to work for free to essentially become you know content creators for El Zivier nobody wants that anymore. So there's a rebellion that's bringing an academia you can see this on twitter you can see this as a journal editor where it's getting harder and harder to find qualified reviewers because people are simply fed up with a lot of the system in its current incarnation. And so what's the alternative? So there's a void and the void that's happening right now is that there's a direct model that's becoming more and more common essentially it goes from preprint platforms directly to social media directly to a journalist who's interested in generating clicks over sharing valid knowledge and this is a this is a a track to our epistemic comments you have that you have spectacular cases for example the hiv gene insertion in that COVID preprint right which has been debunked but the damage has been done and there's still a lot of people out there believing that COVID does h has hiv inserts into into its virus so so that these information hazards tend to live in conspiracy silos tend to live but as governments and institutions are losing trust these conspiracy silos are growing and there's more and more people that are being radicalized to believe things that come forward to preexisting ideas that they might have which might be flawed and the question is well this is perhaps you know one of the greatest responsibility for DSI and one of the greatest hopes we have is can we create a system that addresses some of these press pressing problems about the quality of our information spheres right now.
this one of this idea one of these ideas that can be very powerful is this notion of open verifiability open verifiability is the idea that anyone can take a research object the piece of public research that is accompanied by artifacts and essentially add a validation grant and by adding that validation grant that would go to it would be earmarked to a scientific society with a certain reputation level it would then start producing the validation work right it would essentially be creating our epistemic comments at a high level in caring for things such as reproducibility and simply today this this absolutely does not exist verification is done at the behest of scientists who submit their work to journals so I want to talk about a broader vision for DSI and how what are the components that need to be in place so that we can create this this ideal of open verifiability first of all we need different models of storing and archiving research papers and research audit facts we need to move away from silos that are controlled by publishers or by an operating company that are essentially closed off for repositories which might have access rules into a model where we have gateways right gateways that are essentially cylinders where you can create a research object that gets indexed on a universal record that is immutably open access and our goal with the design for structured for building is how can we create a maximally robust secure and fair principles for knowledge graphs.
the second thing and this is very important if DSI is to gain scientific legitimacy in the scientific sphere we need to come up with a better version of record the version of record is essentially right now defined as the publisher published pdf all right that's the version of record we need to move the version of record away from a simple manuscript that stands on its own towards a research objects with contain artifacts tied to that research for example data for example code for example reproducible container all or even that a a results presentation all of those objects need to be in the same place aggregated in a decentralized repository which cannot be closed off and and put behind paywalls and we need to increase the certifications code right now we're verifying manuscripts we're not looking beyond manuscripts we need to to to do peer review conduct peer review and conduct scientific expert high level scientific validation on the entire object we have to check if it's reproducible we have to to essentially verify its its properties and that's what we call attributes we're going to get back to that and verifiability today is closed right is done at the behest of authors and my author i have a manuscript i send it to major and they'll come back with peer reviews which are often closed and i'm the only one essentially who has a lever on the on the graph of knowledge where i can i can elicit expert feedback right the the other part that is of course post publication peer review but there's no way to incentivize in a high quality post publication peer review right now and so this idea cannot work if we do not have a different model of value capture. 
Value capture right now is happening is essentially entirely captured by the scientific publishers as i do work as an editor or as a peer review as part of a journal i'm doing that on a on a pro bono basis right all the revenue that is generated from selling the work that goes into these journals or or or through apc's author publishing cost because as an author you have to pay to publish that's the model for open access all of that value goes directly into the coffers of the publishers and scientists don't see any of it and that's a incredibly unfair status quo and the deal would go something something like that it's like well we could actually do high quality scientific validation we could check for reproducibility we could go in depth we could do a much better job but that's not going to happen in the current model in which i feel like a content creator for else you've year and that's fair so i want to go zoom out a bit and take you know a bit more of an academic mantle here um what does it mean to be published so we have all these anachronistic uh terms when it when it when we're talk about scientific curation right we say we have preprints preprints to understand it's not published it's not peer reviewed a published paper has a number of properties right so published paper has a set of attributed uh of attributes which have been verified by trusted intermediate area and that's the certification function uh one of them is is it sound are the conclusions warranted given the the the results uh and the methods convey the other one is impact predictions right and this is you know the the much maligned uh is it novel enough for nature right and uh are the conclusions important so essentially have an editor and peer reviewers and maybe an editorial board they're all working to try to make a prediction if that particular piece of object that has been that has been decided as valid by peer reviewers has essentially a conclusion of a scope that is of broad interest enough to be featured in some of these top journals which are essentially have a monopoly on scientific prestige and guide decisions of funders and massive grant allocations um and there's of course the big elephant in the room right nobody checks for very for reproducibility are the result reproducible with the artifacts provided and there's one exception to this rule and I think this is something people don't know it's the American economic association with its flagship journal the American economic review has an incredibly rigorous peer review system in which after it has conducted peer review for soundness for impact prediction it then verifies for reproducibility and that's you know that that's not something that a lot of people know and when you look at the academics uh uh uh uh taxonomy of journals you have journals that only verify for soundness like plus you have journals like you know the the the the science nature cell they'll verify they'll they'll they'll they'll essentially certify for soundness and impact and make a prediction on impact and the American Economic Association on top of all of this will verify for reproducibility by asking authors you know to put under to sender code then their data and have a a number of scientists working with them verifying that the results reproduce so that's the level of uh rigor that goes far beyond what we have in the in the in the classic sphere of journals and one of the reasons why the American Economic Association does that and not let's say an LZB journal is that the scientific society has retained its publishing arm and has therefore been investing in improving at a cost right things that go beyond uh the PDF because there's only a business model for the PDF um and of course there are organizations outside this code that have been doing badging systems right and these badging systems have been designed to essentially provide alternative markers of quality right to think of those as alternative attributes so for example has the study been pre-registered um you have the this is from the center of open science who have been pioneers by the way in in creating these badging systems and it has been followed by yes ACM that's the association for computing machinery they have done badges you know have you shared your artifacts or your artifacts reproducible so when you think about it um journals essentially convey attributes to pieces of published research now can we unbundle the implicit make it explicit and I think that's one of the promising thing about designee alternative publishing system is that yes we can do that um we can essentially treat a research object as having a set of attributes that are verifiable and that are clearly indexed in a way which can per proof on a on a on a decentralized ledger so the idea is that um we unbundle these attributes uh the authors can self select them right and then you have research communities that verify them anyone can contest the presence of these attributes add these validation grants and essentially elicit this high quality scientific validation on these attributes and you have things you know that go from the work is simply compliant right this means you know authors identity self-inverified no plagiarism all the really basic checks but then you can have things you know as the data being shared yes it's open data if the data is restrained access is there a path where I can actually know how to access that data which is very often something that's completely missing from studies that have that that use sensitive data are the results reproducible right can I run an executable container or can I run the code locally with the data set and reproduce those results um is it has it been peer reviewed all of those core functions that have been previously bundled in journals in a way that has you know extracted value from scientists can be decoupled and unbundled to create these rich research objects which have a plurality of attributes now of course you might say well there's never going to be an attribute system to roll them all and that's absolutely true and that's why it's important that organization you know maybe research rub, scurve, others out there can issue their own attributes right so you'd you'd go defining your attribute you'd maintain it you'd set permissions on who can actually verify it you can create we can create plural systems of attribute verification which would allow us to improve the reproducibility in the trust placed into scientific results of course to do this efficiently we need a way to aggregate all of the research outputs so we need a way to essentially combine a preprint repository with a generalist repository is where we can take all of those components like you see on on the side and essentially connect the front end of the paper with the back end which are all of these artifacts that are stored on these decentralized repository and by doing that by creating that interface where you can see and verify all of this we essentially facilitate a system for attribute verification which can be crucial and important in how in in in essentially improving our epistemic comments and our ability to appraise scientific knowledge and this could lead you know to things like proof of reproducibility which are incredibly valuable to funders right now funders they have no way of verifying whether a scientist that I fund with millions of dollars every year actually publishes reproducible research there's no in this in this tracking that and that's one of the things where desiccantatremendous value in that workflow so let me uh i'm going to shift to a little demo so we've seen that at eFansardam we're now in alpha so we're we're testing the interface we're going to be starting indexing to index on chain pretty soon on testnet so the idea here is you can take any PDF right you can take any PDF you can submit it to desi you can start creating a research object and once you've created a research object there will be an embedding right which is what you see up there which is essentially an immutable link to to the node id so to the to the identifier of that research object which is applicable and resolvable and once you're into that interface you can now directly interact with all of the components of that research object so here it's a paper on snarks you can for example very relevant to these types of papers as posting artifacts such as code right so you can start adding codes directly into your paper you can add you know result presentation deck you can add a video you can do all sorts of aggregation to create a reproducible artifacts and you can connect all of this together in a way that's very easy for scientists to use because I think and we're we're strongly of the belief that this needs to be a 20 minute process people need to have excellent UI for all of this this is the only way we're going to gain adoption and essentially you can drag and drop code files you can indicate where people can actually find a relevant raw materials to recreate the results that are presented inside here right you can annotate it freely and what I want to draw your attention to today is this idea of attributes right this open verifiability so here for example we have attributes from the ACM things like RDR defects available right and what is the status on this attribute that has been self-selected by author has it been verified in this case yes and these attributes need to have a number of components to to essentially verify that their conditions are met we need to have a known issue there needs to be a versioning that's on behalf of the issue there needs to be information about who's the certifying entity of the attribute there needs to be proof that this attribute is warranted right in some way and by doing this aggregation model on these design outs where you can combine all of these objects we can essentially create a system where it is legible and simple well simple it's still a lot of work but it is possible to validate these attributes and to improve our epistemic comments and to improve the ability to create reproducible signs you can add validation grants the ideas for example you you you say hey I want to verify attributes I would pick an arc this is of course a demo but essentially the idea is that anyone can be able to mend those validation grants to to have them a pift or not right because these are grants by scientific societies that would then be producing the certification process which journals have been doing up to now and the system is complementary to the existing system I think that's very important to stress is that well we can still have the journal system you know doing curation and then we can have scientific societies that might be wanting to do reproducibility analysis right you might have scientific societies that do the whole thing so this is a place where people and communities can start to experiment with the scope of the type of work that they engage in yeah so essentially we don't want to have a silo we don't want to be hey you have to go on desi.com slash desino to use this platform that's not the ethos of what three that's not the ethos of a decentralized system that's where we're creating an open source stack where every community can run their own gateway right every community can set up a desigate way which is a deployable kit which allows scientists and members of their community to create these research objects and to index them on a desig registry now our goal is to create the most durable verifiable and fair knowledge graph possible right so that means we're mostly tech agnostic but we are using the existing tech stack that we're displaying here so essentially we're creating the research object on a cloud interface then we use a ipld to store that data model in a j's on ld compliant fashion and we in we we stored and on the ipfs network through the work of those gateways those community gateways and we take the root hash of that using optimism we index it on a desig registry which is in the term smart contract which essentially provides tamper proofness regarding that specific object and more importantly it provides immutable pide persistent identifiers now everything in a desigate can be cited we can every component of it has a persistent identifier that can be copied and cited anywhere and it's not at risk of link rot it's cryptographically secured but of course the most important thing for all of this regardless of the infrastructure we're building regardless of these building blocks is communities and that's why we need to have we need to have legit and high quality scientific communities ready to take the risk of of working and and and essentially you know flying from their own wings and having that experience of recapturing the value that they create by creating science and this is you know there's a lot of concepts floating around that we're thinking about how can we make these communities inspiring how can we facilitate the community coordination that is involved around verifying these research objects and this community layer we're not there yet but we're working on it and it's something that's that's going to be very important for essentially curating these objects and we can imagine these communities as collecting and curating a collection of featured work right these are the nodes of the research objects that the community feels most proud of that means the most to them and that exemplifies the type of work that they are capable of and we're super excited for this future right now there's many terms there's arts autonomous research communities DRC decentralized research centers research hubs and I think you know one of the very exciting concept that has been appearing in past months is the concept of these decentralized society which is a blueprint on how we can scale and we can create these communities that essentially create these plural network goods while tracking reputation and identities of their members and science is a perfect experimental ground for that because scientists need to show to the world what they're capable of and we need to to to to to enable that in a way that is better than what has been done before and so these are really some of our of our dreams and aspirations for the future of these side and yeah thank you for your attention alpha is live we're testing on nodes.desai.com thank you to my wonderful team who has been growing and it's just been a blast working with everybody so yeah happy to take questions yeah thank you Chris there's a great presentation really exciting vision excited to see where your alpha goes so we have a couple questions here the next three minutes from Shady and I'll break them down into three parts first one is what are your expectations for how status quo in trends industry players will respond to the site. So it depends right there's shareholders might react negatively but the people making the decisions and the people that actually are mission driven they will react positively because they know they have a problem the APC model charging $10,000 for scientists to have the privilege to publish this work they know it's not sustainable that's that's that's a conversation we've been having and there's that there's that definite feeling that the system as it stands cannot continue and they're desperately looking for different models and if we can create a system that complements right it doesn't need to compete that can complement the existing industry by adding value in terms of reproducibility this is how we gain legitimacy in the scientific sphere right this is how we show our value the value of D-Side that we're not just about buzzwords in web 3 no we're actually about creating a better more reproducible scientific record and here's proof of that awesome thank you next question is what does the attack surface look like for a D-Side protocol. Okay so the the the big problem is identity spoof it right so and this is also not just a problem that's specific to D-Side right you've also can also have identity spoofing on archive you can also have identity spoofing you know orchid there is a problem with identity spoofing right and we need ways to essentially to link to create a gradient of trust around the scientists the scientists that post their work to verify their own entities and to essentially have some measure of confidence that they are who they who they they say they are right and this we're super excited working with Shadian his team with holon them you know there's many many interesting things in the space of identity that are burgeoning up and this has been just accelerating since the D-Side paper right which has been a catalyst for all of that and we're super excited to see you know the type of solutions that that come up but essentially the problem of identity spoofing is is a is a very important problem and then finally how do we engineer resilient protocols that survive long enough to up with the publishing industry through transformational change and then he also said sorry for having such hard questions but you're doing a great job answering them I love those questions yeah open source decentralized community gateways right should the we are building a protocol that does not depend on the continued operation of these silos right and I think that's fundamental as a scientist that's the only reason I mean that's that's a prerequisite for me to use it right I want essentially to be to to have the ability to put my work on a peer to peer system where where these multiple desigate ways reinforce each other creating network effect for each others and start you know writing on this on this desig registry and start accumulating and creating a graph of knowledge that is reproducible that has parameter data that has all these other properties in a way that is that nobody can shut down access to right there's no paywalls that can be put in front of it right the system is built in to be designed such that Elziveer cannot buy it out and shut it down right it has to be slippery right just like BitTorrent except it needs to of course be very legal to use right so I think that's very important we need to like remain within the the precise confines of the law we have to do everything by the bookstore and we need to essentially empower communities with base layers that they can use and and and operate in an open source fashion awesome thank you and Chris if you're okay with it it sounds like we have a couple more questions if you want to hang around for another five minutes or so sure sure I'm gonna happy so I yeah I wanted to ask you a couple questions since you touched on reproducibility there's something I really care about and I just like recently wrote a piece on research on you know how to potentially you know take this better a question I have is do you think is there a way to kind of like you know decentralized the work of verifying reproducibility for a study this is what this was always in that in a way that we can kind of like create a decentralized consensus on scientific claims so we have different kind of like research groups trying to like replicate a study and see who fails who does not fail because we also have to take into account even whenever that's something that you know might happen so there's really two different things here there's reproducibility and replicability right so for those that don't know reproducibility can I recreate the studies result given the available artifacts whereas replicability is you know I use new artifacts you know new code that collect new data and can I come back to the results right so these are two different things they have their own associated challenges right which are very very important and this is a by the way this is this is the the problem in science not from from from our point of view it's the lack of reproducible and replicability and if you talk through scientists that they'll say yes that's the problem the way we can do that we think is that we have to emulate structures that have been functioning for example the ACM SIGM conferences have been verify ACM badges the American Economic Association has been verifying reproducibility of research they have a culture and they have processes in place to do this we have to learn from them and we have to then create a knowledge base that we can essentially a couple with these these Rx these autonomous research kits right that can be deployed by these communities so that they can effectively conduct replication evaluation right and that that requires of course a lot of learning there's a lot of community leadership that needs to be done but the the fundamental thing here is that it's now the scientific societies that recaptured a value right it doesn't go to the publisher so all of a sudden your research community can create fellowships right for its PhD students they don't need to live under the poverty line anymore could be you know just just you know 500 die a month that would go a long way in improving the situation of a student and as a PI or as a senior scientist I would feel a responsibility you know to to to help my guys out and you can now do that we could orchestrate we can create community coordination structures that allow for that that that that specific goal of certify reproducibility while you know returning value to scientists which can be re-injected in the in the accounts of people that needed the most the early career researchers yeah thank you that that was that was really a very nice explanation actually also you know getting into the difference that is really important between reproducibility and replicability so we actually have another one from the audience what are your thoughts about reproducibility and immutability with the fact that many role data sets and metadata specifically in social media and healthcare are personally information that protected by right to be erased thank you that's what I mean great question right so there's there's different ways to address that one of the thing is we want to make clear do not put restrained access data on desirata right that is not something that is appropriate the reason is there's all sorts of regulation that essentially gate the rights to especially human data right which is very very sensitive and we have to be extremely mindful of the sensitive video of that type of data however you can create a component which is called a restrained data access notice right and that component is essentially a metadata set which tells the reader where he can find the restrained access data how he can access it what are the conditions of access and that is preserve the mutable now that has a lot of value because this is something right now that is lacking there's there's very little clarity in accessing in the conditions of access to restrained access data and what does that mean now if you create a system in science where every study is expected to be reproducible do we just say okay we give these guys you know free pass they don't need to have reproducible results because their data is restrained access we can't do it no right that doesn't work that's a that's a that's a monumental problem and that's why it's important to know who's act who has the right to access it so that's communities that do the scientific verification services they can actually have members that might have access to that data right that would do it within the trusted bounds of their institutions and so that's essential.