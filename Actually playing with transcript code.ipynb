{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5648b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import os\n",
    "import openai\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# This function pulls the transcript of YouTube videos, then writes the individual \n",
    "# lines coming from youtube into an individual text file\n",
    "def FormatYouTubeTranscript(video_id,path):\n",
    "    \n",
    "    # Pulls transcript from youtube\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "    # Preliminary code needed to initialize text cleaning\n",
    "    filename = path + \"transcript_\" + video_id + \".txt\"\n",
    "    F = open(filename, \"w\")\n",
    "    transcript_text = \"\"\n",
    "\n",
    "    # Appends each line from youtube into a text file and a transcript string\n",
    "    for index in range(len(transcript)):\n",
    "        line = transcript[index]['text'] + \" \"\n",
    "        F.write(line)\n",
    "        transcript_text+=line\n",
    "\n",
    "    F.close()\n",
    "    return transcript_text\n",
    "\n",
    "\n",
    "# This function takes the text input from the youtube video and uses GPT3 to turn it into a cohesive \n",
    "# series of thoughts. Those can later be turned into a twitter thread\n",
    "def CreateModularContent(openai, transcript_text, path):\n",
    "    \n",
    "    # Imports GPT3 model. Using Curie as it does a good job of summarizing text at a significantly cheaper\n",
    "    # rate than DaVinci\n",
    "    openai.Model.retrieve(\"text-curie-001\")   \n",
    "\n",
    "    # The text is summarized in 1000 word chunks. GPT3 limits text size on inputs. 1000 word segments \n",
    "    # are large enough to yeild complete and relevant thoughts. \n",
    "    countOfWords = len(transcript_text.split())\n",
    "    n = 1000\n",
    "    \n",
    "    # Preliminary code needed to initialize text cleaning\n",
    "    #filename = path + \"summary_\" + video_id + \".txt\"\n",
    "    #F = open(filename, \"w\")\n",
    "    filename2 = path + \"transcript_1000_word_chunks_\" + video_id + \".txt\"\n",
    "    F2 = open(filename2, \"w\")\n",
    "\n",
    "\n",
    "    # Prompts to ask GPT3\n",
    "    prompts = [\n",
    "        [\"Summarize this text into a paragraph:\",\n",
    "        \"What is the most significant problem this text identifies:\",\n",
    "        \"What is the supporting evidence for the problem:\",\n",
    "        \"What is the solution to the problem:\",\n",
    "        \"What are the limitations of the proposed solution:\",\n",
    "        \"What does the text conclude\"],\n",
    "        [\"Elaborare on the 5 main points discussed in this text.\"]\n",
    "    ]\n",
    "\n",
    "    sleepCounter = 0\n",
    "    progressCounter = 0\n",
    "    totalIterations = (math.ceil(countOfWords/n)*2-1) * len(prompts[0])\n",
    "\n",
    "    # for loop that analyzes community call text using GPT3\n",
    "    for t in range(math.ceil(countOfWords/n)*2-1):\n",
    "    #for t in range(1):\n",
    "\n",
    "        # text start and end counters\n",
    "        start = int(round(t * n/2))\n",
    "        end = int(round((t+2) * n/2))\n",
    "        text = ' '.join(transcript_text.split()[start:end])\n",
    "\n",
    "        # .txt formatting\n",
    "        F2.write(str(start))\n",
    "        F2.write(\"\\n\")\n",
    "        F2.write(str(end))\n",
    "        F2.write(\"\\n\\n\\n\")\n",
    "        F2.write(text)\n",
    "        F2.write(\"\\n\\n--------\\n\\n\")\n",
    "        \"\"\"\n",
    "        # .txt formatting\n",
    "        F.write(str(start))\n",
    "        F.write(\"\\n\")\n",
    "        F.write(str(end))\n",
    "        F.write(\"\\n\")\n",
    "\n",
    "        # Iterate over various prompts about a block of text\n",
    "        for p in prompts[0]:\n",
    "\n",
    "            # It's rude that I have to do this\n",
    "            sleepCounter+=1\n",
    "\n",
    "            # A sleep counter because microsoft keeps limiting my creativity\n",
    "            if sleepCounter%30==0 and sleepCounter!=0:\n",
    "                print(\"\\n\\n\\nI am so sleepy\\n\\n\\n\")\n",
    "                time.sleep(60)\n",
    "\n",
    "            # Model parameters were determined through sandbox testing. Temp is fairly high to allow the model\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-curie-001\",\n",
    "                # prompt = \"Create a list of the main points in this text.\" + \"\\n\\n\" + text + \"\\n\\n\",\n",
    "                prompt = p + \"\\n\\n\" + text + \"\\n\\n\",\n",
    "                max_tokens=400,\n",
    "                temperature=0.7,\n",
    "                frequency_penalty=0.2,\n",
    "                presence_penalty=0.2\n",
    "            ) \n",
    "            \n",
    "            # answer logging and .txt formatting\n",
    "            F.write(\"\\n\\n\\n\" + p)\n",
    "            F.write(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "            progressCounter+=1\n",
    "            print(\"\\n\" + str(progressCounter) + \" of \" + str(totalIterations) + \"\\n\")\n",
    "            print(\"\\n\"+p+\"\\n\")\n",
    "            print(response[\"choices\"][0][\"text\"])\n",
    "        \n",
    "        # .txt formatting\n",
    "        F.write(\"\\n\\n--------\\n\\n\")\n",
    "        \"\"\"\n",
    "\n",
    "    F2.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = '/Users/desot1/Documents/transcript_project'\n",
    "video_id = '7q7rij0Wv5g'\n",
    "\n",
    "#openai.organization = \"org-6VHyHADPuVpvaocpiGuAUaPb\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "transcript_text = FormatYouTubeTranscript(video_id,path)\n",
    "CreateModularContent(openai, transcript_text, path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9b1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
